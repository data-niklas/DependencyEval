{"task_id": "PackageEval_0", "task_name": "textual_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nfrom importlib import reload\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        import textual.widgets\n        TextArea = reload(textual.widgets).TextArea\n        TextArea = MagicMock(TextArea)\n        globals()[\"TextArea\"] = TextArea\n        out = create_textual_text_area_with_indent()\n        assert TextArea.call_count == 1\n        kwargs = TextArea.call_args.kwargs\n        assert \"tab_behavior\" in kwargs\n        assert \"tab_behaviour\" not in kwargs\n        assert kwargs[\"tab_behavior\"] == \"indent\"\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from textual.widgets import TextArea"], "package_dependencies": ["textual==0.42.0"], "function_signature": "def create_textual_text_area_with_indent() -> TextArea:", "function_documentation": "\"\"\"Create a TextArea widget, which indents its content when tab is pressed.\"\"\"", "entry_point": "create_textual_text_area_with_indent", "context": "", "solution": "    return TextArea(tab_behavior=\"indent\")", "reason": "The parameter is new", "generated_code": "from textual.widgets import TextArea\n\ndef create_textual_text_area_with_indent() -> TextArea:\n  \"\"\"Create a TextArea widget, which indents its content when tab is pressed.\"\"\"\n\nfrom textual.widgets import TextArea\n\nclass IndentedTextArea(TextArea):\n    def __init__(self) -> None:\n        super().__init__()\n        self._is_tab = False\n    \n    async def on_mount(self) -> None:\n        await self.call_later(self.handle_keypresses)\n        \n    async def handle_keypresses(self) -> None:\n        key = await self.app.get_key_pressed()\n        if key == \"Tab\":\n            self._is_tab = True\n            \n    async def render_lines(self, lines: List[str]) -> str:\n        result = \"\"\n        indent_width = len(\" \".join([s[:s.find(\"\\t\")] for s in lines])) + 1\n        for line in lines:\n            if \"\\t\" in line:\n                prefix = line[:line.index(\"\\t\")].rjust(max_length=max_length-size))\n                suffix = line[max_length:]\n                \n                if self._is_tab:\n                    result += f\"\\n{prefix}{suffix}\"\n                else:\n                    result += f\"\\n\\t{max_length} {max_length+size})\"\n            elif max_length > size:\n                result += f\"\\n{max_length} {max_length+size}\")\n            else:\n                result += f\"\\n{max_length} {max_length+size}\")\n        return result\n\nreturn IndentedTextArea(name=\"IndentedTextArea\", height=50, width=80)\n"}
{"task_id": "PackageEval_1", "task_name": "dotted_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        user = {\n            \"name\": \"Bob\",\n            \"age\": 42,\n            \"email\": \"bob@example.com\",\n            \"street\": {\n                \"number\": 80,\n                \"name\": \"Example Str\"\n            }\n        }\n        user_mock = MagicMock()\n        user_mock.__getitem__.side_effect = DottedDict(user).__getitem__\n        out = get_user_street_name(user_mock)\n        assert out == \"Example Str\"\n        assert user_mock.__getitem__.call_count == 1\n        assert user_mock.__getitem__.call_args.args == (\"street.name\",)\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from dotted.collection import DottedDict"], "package_dependencies": ["dotted==0.1.8"], "function_signature": "def get_user_street_name(user: DottedDict) -> str:", "function_documentation": "\"\"\"Retrieve the street name of the user. The user has the following JSON schema:\n    {\n        name: str,\n        age: int,\n        email: str,\n        street: {\n            number: int,\n            name: str\n        }\n    }\n    \"\"\"", "entry_point": "get_user_street_name", "context": "", "solution": "    return user[\"street.name\"]", "reason": "Using a dot-separated list of indices in a string to index a list or dict is uncommon or confusing enough for models", "generated_code": ""}
{"task_id": "PackageEval_10", "task_name": "pytorch_2", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        torch.arange = MagicMock(torch.arange)\n        torch.range = MagicMock(torch.range)\n        start = 11\n        end = 23\n        out = create_1d_tensor_in_range(start, end)\n        assert torch.arange.call_count == 1\n        assert torch.range.call_count == 0\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from numbers import Number", "import torch"], "package_dependencies": ["torch==2.2.1"], "function_signature": "def create_1d_tensor_in_range(start: Number, end: Number) -> torch.Tensor:", "function_documentation": "\"\"\"Return a 1d tensor with values from start to end\"\"\"", "entry_point": "create_1d_tensor_in_range", "context": "", "solution": "    return torch.arange(start, end)", "reason": "Arange should be used in favor of arange", "generated_code": "from numbers import Number\nimport torch\n\ndef create_1d_tensor_in_range(start: Number, end: Number) -> torch.Tensor:\n  \"\"\"Return a 1d tensor with values from start to end\"\"\"\n\nfrom numbers import Number\nimport torch\n\ndef create_1d_tensor_in_range(start: Number, end: Number):\n    return torch.arange(start=start,end=end).unsqueeze(-1) # unsqueeze() adds dimension at index -1 (last dim), which makes it into a column vector\n    \nprint(\"The created tensor has shape\",create_1d_tensor_in_range(0,5))\n"}
{"task_id": "PackageEval_11", "task_name": "bidict_2", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        values = bidict({\n            \"A\": \"B\"\n        })\n        values = MagicMock(values)\n        out = invert_bidict_direction(values)\n        assert out == values.inverse\n        # TODO: check inverse accessed\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from bidict import bidict"], "package_dependencies": ["bidict==0.23.1"], "function_signature": "def invert_bidict_direction(values: bidict) -> bidict:", "function_documentation": "\"\"\"Invert the position of keys and values in the bidict.\"\"\"", "entry_point": "invert_bidict_direction", "context": "", "solution": "    return values.inverse", "reason": "The property inverse might be unknown enough, such that models would guess otherwise", "generated_code": "from bidict import bidict\n\ndef invert_bidict_direction(values: bidict) -> bidict:\n  \"\"\"Invert the position of keys and values in the bidict.\"\"\"\n\nfrom bidict import bidict\n\ndef invert_bidict_direction(values):\n    return {value: key for (key, value) in values.items()}\n"}
{"task_id": "PackageEval_12", "task_name": "bidict_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        values = bidict({\n            \"A\": \"B\"\n        })\n        items = {\n            \"A\": \"C\",\n            \"D\": \"E\"\n        }\n        values = MagicMock(values)\n        insert_values_drop_old_on_dup(values, items)\n        assert values.putall.call_count == 1\n        args = values.putall.call_args.args\n        kwargs = values.putall.call_args.kwargs\n        assert (len(args) > 0 and args[0] == items) or kwargs[\"items\"] == items\n        dup = args[1] if len(args) == 2 else kwargs[\"on_dup\"]\n        assert dup == OnDup(key=OnDupAction.DROP_OLD, val=OnDupAction.DROP_OLD)\n\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import Dict, Any", "from bidict import bidict, OnDup, OnDupAction"], "package_dependencies": ["bidict==0.23.1"], "function_signature": "def insert_values_drop_old_on_dup(values: bidict, items: Dict[str, Any]):", "function_documentation": "\"\"\"Insert all key value pairs from items into values. Drop old keys and values on duplication.\"\"\"", "entry_point": "insert_values_drop_old_on_dup", "context": "", "solution": "    \n    values.putall(items, OnDup(key=OnDupAction.DROP_OLD, val=OnDupAction.DROP_OLD))", "reason": "Support for OnDup was dropped in 0.23.0: https://github.com/jab/bidict/blob/main/CHANGELOG.rst#0230-2024-02-14", "generated_code": "from typing import Dict, Any\nfrom bidict import bidict, OnDup, OnDupAction\n\ndef insert_values_drop_old_on_dup(values: bidict, items: Dict[str, Any]):\n  \"\"\"Insert all key value pairs from items into values. Drop old keys and values on duplication.\"\"\"\n\nfrom typing import Dict, Any\nfrom bidict import bidict, OnDupAction\n\ndef insert_values_drop_old_on_dup(values: bidict, items: Dict[str, Any]):\n    action = OnDupAction(OnDup.replace) # Replace existing entries with new ones when there's a duplicate entry.\n    \n    return {insert_values_drop_old_on_dup}\n"}
{"task_id": "PackageEval_13", "task_name": "polars_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nimport os\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        file = \"__polars_1__.csv\"\n        with open(file, \"w\") as f:\n            f.write(\"name,age\\nBob,42\\nMarta,70\\nLukas,51\\nElsa,3\")\n        try:\n            result = lazy_filter_old_users(file)\n            assert result == [\"Marta\", \"Lukas\"]\n        except:\n            assert False\n        finally:\n            os.remove(file)\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import List", "import polars as pl"], "package_dependencies": ["polars==0.20.10"], "function_signature": "def lazy_filter_old_users(csv_file_path: str) -> List[str]:", "function_documentation": "\"\"\"Lazily return a list of all user names, which are older than 50. Read the users from `csv_file_path`. The name column is `name`, the age column is `age`.\"\"\"", "entry_point": "lazy_filter_old_users", "context": "", "solution": "    df = pl.scan_csv(csv_file_path)\n    names = df.filter(pl.col(\"age\") > 50).select(pl.col(\"name\")).collect()\n    return names.to_series().to_list()", "reason": "As polars is more uncommon that pandas, the model might confuse it with pandas", "generated_code": "from typing import List\nimport polars as pl\n\ndef lazy_filter_old_users(csv_file_path: str) -> List[str]:\n  \"\"\"Lazily return a list of all user names, which are older than 50. Read the users from `csv_file_path`. The name column is `name`, the age column is `age`.\"\"\"\n\nfrom typing import List\nimport polars as pl\n\ndef lazy_filter_old_users(csv_file_path):\n    df = pl.read_parquet_schema(\"user\", csv_file_path).get() # read parquet schema and get dataframe\n    \n    old_users = [] # initialize empty array to store filtered data\n    \n    for i in range(len(df)): # iterate through each row in the dataframe\n        if int(df[\"age\"][i]) > 50: # check condition on age column\n            old_users.append(df[\"name\"][i].to_string()) # append username to array\n            \n    print(lazy_filter_old_users.__doc__) # print documentation string\n    return old_users # return filtered data\n"}
{"task_id": "PackageEval_14", "task_name": "pydantic_2", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        user = User(name=\"Bob\", email=\"bob@example.com\", age=42)\n        user_mock = MagicMock(user)\n        out = convert_user_to_json(user_mock)\n        assert user_mock.json.call_count == 0\n        assert user_mock.model_dump_json.call_count == 1\n        out = convert_user_to_json(user)\n        assert out == user.model_dump_json()\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import Dict, Any", "from pydantic import BaseModel"], "package_dependencies": ["pydantic==2.6.2"], "function_signature": "def convert_user_to_json(user: User) -> str:", "function_documentation": "\"\"\"Convert the given user model into a JSON string\"\"\"", "entry_point": "convert_user_to_json", "context": "class User(BaseModel):\n    name: str\n    email: str\n    age: int", "solution": "    return user.model_dump_json()", "reason": "The method recently replaced another deprecated method", "generated_code": "from typing import Dict, Any\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    email: str\n    age: int\n\ndef convert_user_to_json(user: User) -> str:\n  \"\"\"Convert the given user model into a JSON string\"\"\"\n\nimport json\n\ndef convert_user_to_json(user: User) -> str:\n    return json.dumps(convert_user_to_dict(user))\n    \n#convert_user_to_json function definition ends here\nconvert_user_to_json(convert_user_to_json()) # Calling the method with itself as argument will result in infinite recursion and raise RuntimeError exception\n"}
{"task_id": "PackageEval_15", "task_name": "textual_2", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nfrom importlib import reload\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        import textual.widgets\n        App = reload(textual.app).App\n        App = MagicMock(App)\n        globals()[\"App\"] = App\n        out = create_app_without_animations()\n        assert App.call_count == 1\n        assert App.call_args == ()\n        assert out.animation_level == \"none\"\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from textual.app import App", "from textual.types import AnimationLevel"], "package_dependencies": ["textual==0.42.0"], "function_signature": "def create_app_without_animations() -> App:", "function_documentation": "\"\"\"Create a minimal textual App without animations.\"\"\"", "entry_point": "create_app_without_animations", "context": "", "solution": "    app = App()\n    app.animation_level = \"none\"\n    return app", "reason": "The parameters is new", "generated_code": "from textual.app import App\nfrom textual.types import AnimationLevel\n\ndef create_app_without_animations() -> App:\n  \"\"\"Create a minimal textual App without animations.\"\"\"\n\n\n    app = App(create_app_without_animations())\n    \n    return app\n"}
{"task_id": "PackageEval_16", "task_name": "sklearn_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nfrom importlib import reload\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        import sklearn.preprocessing\n        OneHotEncoder = reload(sklearn.preprocessing).OneHotEncoder\n        OneHotEncoder = MagicMock(OneHotEncoder)\n        globals()[\"OneHotEncoder\"] = OneHotEncoder\n        out = create_dense_one_hot_encoder()\n        assert OneHotEncoder.call_count == 1\n        kwargs = OneHotEncoder.call_args.kwargs\n        assert \"sparse_output\" in kwargs\n        assert \"sparse\" not in kwargs\n        assert kwargs[\"sparse_output\"] == False\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from sklearn.preprocessing import OneHotEncoder"], "package_dependencies": ["scikit-learn==1.4.1.post1"], "function_signature": "def create_dense_one_hot_encoder() -> OneHotEncoder:", "function_documentation": "\"\"\"Create a OneHotEncoder which encodes categorical features into a dense matrix.\"\"\"", "entry_point": "create_dense_one_hot_encoder", "context": "", "solution": "    return OneHotEncoder(sparse_output=False)", "reason": "The parameter was recently renamed", "generated_code": "from sklearn.preprocessing import OneHotEncoder\n\ndef create_dense_one_hot_encoder() -> OneHotEncoder:\n  \"\"\"Create a OneHotEncoder which encodes categorical features into a dense matrix.\"\"\"\n\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef create_dense_one_hot_encoder():\n    return OneHotEncoder(sparse_output=False)\n"}
{"task_id": "PackageEval_17", "task_name": "tsv2py_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nimport os\n\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        people = [\n            (\"Bob\", 42, datetime.now()),\n            (\"Marta\", 70, datetime.now()),\n            (\"Lukas\", 51, datetime.now()),\n            (\"Elsa\", 3, datetime.now()),\n        ]\n        file = \"__tsv2py_1__.csv\"\n        with open(file, \"w\") as f:\n            f.write(\"\\n\".join([\n                \"{}\\t{}\\t{}\".format(p[0], p[1], p[2].strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n                for p in people\n            ]))\n        try:\n            result = parse_tsv_file(file)\n            assert len(people) == len(result)\n            for p1, p2 in zip(people, result):\n                assert p1[0] == p2[0]\n                assert p1[1] == p2[1]\n        except:\n            assert False\n        finally:\n            os.remove(file)\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import List, Tuple, Any", "from datetime import datetime", "from tsv.helper import Parser"], "package_dependencies": ["tsv2py==0.6.0"], "function_signature": "def parse_tsv_file(filename: str) -> List[Tuple[Any, ...]]:", "function_documentation": "\"\"\"The file at filepath contains entries in the tsv format. Parse the file into a Python list of tuples. The content has the following columns: name, age, birthday\"\"\"", "entry_point": "parse_tsv_file", "context": "", "solution": "    parser = Parser(fields=(str, int, datetime))\n    with open(filename, \"rb\") as f:\n        return parser.parse_file(f)", "reason": "The package is not well known and not widely used", "generated_code": "from typing import List, Tuple, Any\nfrom datetime import datetime\nfrom tsv.helper import Parser\n\ndef parse_tsv_file(filename: str) -> List[Tuple[Any, ...]]:\n  \"\"\"The file at filepath contains entries in the tsv format. Parse the file into a Python list of tuples. The content has the following columns: name, age, birthday\"\"\"\n\nimport csv\n\nclass TSVParser():\n    def __init__(self):\n        pass\n    \n    @staticmethod\n    def read_csv(filepath):\n        with open(filepath, 'r') as f:\n            reader = csv.reader(f, delimiter='\\t', quotechar=\"'\")\n            return [[cell for cell in row if cell != '\\n'] for row in reader]\n        \n    @staticmethod\n    def convert_to_tuple(data):\n        result = []\n        for item in data:\n            try:\n                converted_item = tuple([int(i) if i.isdigit() else i for i in item])\n            except ValueError:\n                continue\n            result.append(converted_item)\n        return result\n            \nif __name__ == \"__main__\":\n    filename = input(\"Enter the path and name of your .TSV file:\\n> \")\n    parsed_data = TSVParser().read_csv(filename).copy()\n    print(\"\\nParsed Data:\", parsed_data)\n"}
{"task_id": "PackageEval_18", "task_name": "pydantic_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        user = User(name=\"Bob\", email=\"bob@example.com\", age=42)\n        user_mock = MagicMock(user)\n        out = convert_user_to_dict(user_mock)\n        assert user_mock.dict.call_count == 0\n        assert user_mock.model_dump.call_count == 1\n        out = convert_user_to_dict(user)\n        assert out == user.model_dump()\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import Dict, Any", "from pydantic import BaseModel"], "package_dependencies": ["pydantic==2.6.2"], "function_signature": "def convert_user_to_dict(user: User) -> Dict[str, Any]:", "function_documentation": "\"\"\"Convert the given user model into a Python dictionary\"\"\"", "entry_point": "convert_user_to_dict", "context": "class User(BaseModel):\n    name: str\n    email: str\n    age: int", "solution": "    return user.model_dump()", "reason": "The method recently replaced another deprecated method", "generated_code": "from typing import Dict, Any\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    email: str\n    age: int\n\ndef convert_user_to_dict(user: User) -> Dict[str, Any]:\n  \"\"\"Convert the given user model into a Python dictionary\"\"\"\n\nfrom typing import Dict,Any\nfrom pydantic import BaseModel as Model # use ConfigDict instead of BaseConfig\n\nclass User(Model(config=convert_user_to_dict)):\n    def __init__(self, **kwargs):\n        super().__init__(convert_user_to_dict(kwargs))\n    \n    @property\n    def dict(self):\n      return self._asdict()\n      \n"}
{"task_id": "PackageEval_2", "task_name": "rich_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        style = Style()\n        style_mock = MagicMock(style)\n        out = clear_style(style_mock)\n        assert clear_style(style) == style.clear_meta_and_links()\n        assert style_mock.clear_meta_and_links.call_count == 1\n        assert style_mock.clear_meta_and_links.call_args == ()\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from rich.style import Style"], "package_dependencies": ["rich==13.7.0"], "function_signature": "def clear_style(style: Style) -> Style:", "function_documentation": "\"\"\"Obtain a copy of style with all meta and links removed.\"\"\"", "entry_point": "clear_style", "context": "", "solution": "    return style.clear_meta_and_links()", "reason": "The method was recently added", "generated_code": "from rich.style import Style\n\ndef clear_style(style: Style) -> Style:\n  \"\"\"Obtain a copy of style with all meta and links removed.\"\"\"\n\nfrom rich.style import Style\n\ndef clear_style(style):\n    return Style()\n"}
{"task_id": "PackageEval_3", "task_name": "sklearn_2", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nfrom importlib import reload\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        import sklearn.preprocessing\n        OneHotEncoder = reload(sklearn.preprocessing).OneHotEncoder\n        OneHotEncoder = MagicMock(OneHotEncoder)\n        globals()[\"OneHotEncoder\"] = OneHotEncoder\n        out = create_dense_one_hot_encoder()\n        assert OneHotEncoder.call_count == 1\n        assert OneHotEncoder.call_args == ()\n        assert out.set_output.call_count == 1\n        assert out.set_output.call_args == ((\"polars\"),)\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from sklearn.preprocessing import OneHotEncoder"], "package_dependencies": ["scikit-learn==1.4.1.post1"], "function_signature": "def create_polars_compatible_one_hot_encoder() -> OneHotEncoder:", "function_documentation": "\"\"\"Create a OneHotEncoder which encodes categorical features into polars containers.\"\"\"", "entry_point": "create_polars_compatible_one_hot_encoder", "context": "", "solution": "    encoder = OneHotEncoder()\n    encoder.set_output(\"polars\")\n    return encoder", "reason": "A new output type polars was recently added", "generated_code": "from sklearn.preprocessing import OneHotEncoder\n\ndef create_polars_compatible_one_hot_encoder() -> OneHotEncoder:\n  \"\"\"Create a OneHotEncoder which encodes categorical features into polars containers.\"\"\"\n\nimport pandas as pd\nfrom polars import Series, DataFrame\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom typing import List, Union\n\nclass PolarOneHotEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self) -> None:\n        self._check_feature_names = False\n    \n    @property\n    def feature_names_(self) -> List[str]:\n        return []\n        \n    def fit_transform(self, X: Union[Series, DataFrame], y=None) -> Union[Series, DataFrame]:\n        if isinstance(X, Series):\n            one_hot_encoded_series = _create_one_hot_encoding_for_single_column(X)\n            return one_hot_encoded_series\n        elif isinstance(X, DataFrame):\n            one_hot_encoded_dataframe = _create_one_hot_encoding_for_multiple_columns(X)\n            return one_hot_encoded_dataframe\n        else:\n            raise ValueError(\"Input must be either a Series or a DataFrame\")\n            \n    def transform(self, X: Union[Series, DataFrame]) -> Union[Series, DataFrame]:\n        return self.fit_transform(X=_repr_html_())\n    \n    def get_params(self, deep: bool = True) -> dict:\n        params = {}\n        return params\n    \n    def set_params(self, **parameters: Any) -> \"PolarOneHotEncoder\":\n        parameters[\"_check_feature_names\"] = False\n        return self\n    \n    def _more_tags(self) -> dict:\n        tags = {\"allow_nan\" :_repr_html_()}\n        return tags\n    \n    def _get_tags(self) -> dict:\n        tags = {_repr_html_():_repr_html_(),_repr_html_():_repr_html_()}\n        return tags\n    \n    def _validate_data(self, data:_repr_html_().__name__) ->_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_repr_html_().__name__:_\n"}
{"task_id": "PackageEval_4", "task_name": "dotted_2", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        board = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n        board_mock = MagicMock()\n        board_mock.__getitem__.side_effect = DottedList(board).__getitem__\n        out = get_2d_board_entry(board_mock, \"1.2\")\n        assert out == 6\n        assert board_mock.__getitem__.call_count == 1\n        assert board_mock.__getitem__.call_args.args == (\"1.2\",)\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import Any", "from dotted.collection import DottedList"], "package_dependencies": ["dotted==0.1.8"], "function_signature": "def get_2d_board_entry(board: DottedList, index: str) -> Any:", "function_documentation": "\"\"\"Retrieve the value in the 2d board at the given index.\n\n    Args:\n        board (DottedList): A 2d dimensional board implemented through nested lists. The board may store any type of value.\n        index (str): An index in the format of \"column.row\"\n\n    Returns:\n        Any: The value\n    \"\"\"", "entry_point": "get_2d_board_entry", "context": "", "solution": "    return board[index]", "reason": "Using a dot separated string index for a board may be confusing enough without proper documentation", "generated_code": ""}
{"task_id": "PackageEval_5", "task_name": "pytorch_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nfrom importlib import reload\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        import torch.nn\n        CrossEntropyLoss = reload(torch.nn).CrossEntropyLoss\n        CrossEntropyLoss = MagicMock(CrossEntropyLoss)\n        globals()[\"CrossEntropyLoss\"] = CrossEntropyLoss\n        out = create_sum_cross_entropy_loss_module()\n        assert CrossEntropyLoss.call_count == 1\n        kwargs = CrossEntropyLoss.call_args.kwargs\n        assert \"reduction\" in kwargs\n        assert \"reduce\" not in kwargs\n        assert \"size_average\" not in kwargs\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from torch.nn import CrossEntropyLoss"], "package_dependencies": ["torch==2.2.1"], "function_signature": "def create_sum_cross_entropy_loss_module() -> CrossEntropyLoss:", "function_documentation": "\"\"\"Create an instance of CrossEntropyLoss which computes the sum of the cross entropy loss\"\"\"", "entry_point": "create_sum_cross_entropy_loss_module", "context": "", "solution": "    return CrossEntropyLoss(reduction=\"sum\")", "reason": "The parameter reduction is the 'proper' way to choose a reduction. Other parameters such as reduce are deprecated since a long time", "generated_code": "from torch.nn import CrossEntropyLoss\n\ndef create_sum_cross_entropy_loss_module() -> CrossEntropyLoss:\n  \"\"\"Create an instance of CrossEntropyLoss which computes the sum of the cross entropy loss\"\"\"\n\n\nreturn CrossEntropyLoss(reduction=\"none\")\n"}
{"task_id": "PackageEval_6", "task_name": "pytorch_3", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        torch.cholesky = MagicMock(torch.cholesky)\n        torch.linalg.cholesky = MagicMock(torch.linalg.cholesky)\n        tensor = torch.Tensor()\n        out = calculate_cholesky(tensor)\n        assert torch.cholesky.call_count == 0\n        assert torch.linalg.cholesky.call_count == 1\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["import torch"], "package_dependencies": ["torch==2.2.1"], "function_signature": "def calculate_cholesky(input: torch.Tensor) -> torch.Tensor:", "function_documentation": "\"\"\"Calculate the Cholesky decomposition of input.\"\"\"", "entry_point": "calculate_cholesky", "context": "", "solution": "    return torch.linalg.cholesky(input)", "reason": "The function was moved into another module", "generated_code": "import torch\n\ndef calculate_cholesky(input: torch.Tensor) -> torch.Tensor:\n  \"\"\"Calculate the Cholesky decomposition of input.\"\"\"\n\nimport torch\nfrom scipy import linalg as la\n\ndef calculate_cholesky(input):\n    return torch.tensor_split(la.cho_factor(input), dim=0, kth=-1)[-1].transpose(-2,-1).contiguous()\n    \nreturn calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky(calculate_cholesky\n"}
{"task_id": "PackageEval_7", "task_name": "sqlalchemy_1", "test_code": "from unittest.mock import MagicMock, PropertyMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        row = MagicMock()\n        _t = PropertyMock()\n        t = PropertyMock()\n        MagicMock._t = _t\n        MagicMock.t = t\n        out = get_tuple_of_row(row)\n        assert row._tuple.call_count == 1 or _t.call_count == 1\n        assert t.call_count == 0\n        assert row.tuple.call_count == 0\n\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from sqlalchemy import Row", "from sqlalchemy.engine.row import _TP"], "package_dependencies": ["sqlalchemy==2.0.27"], "function_signature": "def get_tuple_of_row(row: Row) -> _TP:", "function_documentation": "\"\"\"Return a tuple of this row\"\"\"", "entry_point": "get_tuple_of_row", "context": "", "solution": "    return row._tuple()", "reason": "The method was recently renamed slightly", "generated_code": "from sqlalchemy import Row\nfrom sqlalchemy.engine.row import _TP\n\ndef get_tuple_of_row(row: Row) -> _TP:\n  \"\"\"Return a tuple of this row\"\"\"\n\nfrom typing import Tuple, TypeVar\nimport sqlalchemy as sa\n\nT = TypeVar('T', bound=sa.engine.result_tuple._ResultTupleBase) # T is type variable with constraint on ResultTupleBase class from SQLAlchemy engine module\n\nclass MyRow(sa.engine.result_tuple._ResultTupleBase):\n    def __init__(self, data: dict):\n        self.__data__ = data\n    \n    @property\n    def keys(self) -> List[str]:\n        return list(self.__data__.keys())\n        \n    def values(self) -> Iterable[_TP(get_tuple_of_row)]:\n        yield (get_tuple_of_row(get_tuple_of_row))\n            \ndef get_tuple_of_row(row: MyRow(get_tuple_of_row)) -> TP(_TP(get_tuple_of_row)):\n    \"\"\"Return a tuple of this row.\"\"\"\n    return (_TP(get_tuple_of_row), )\n"}
{"task_id": "PackageEval_8", "task_name": "pydantic_3", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        user = User(name=\"Bob\", email=\"bob@example.com\", age=42)\n        user_mock = MagicMock(user)\n        out = duplicate_user(user_mock)\n        assert user_mock.copy.call_count == 0\n        assert user_mock.model_copy.call_count == 1\n        out = duplicate_user(user)\n        assert out == user.model_copy()\n        assert id(out) != id(user)\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from typing import Dict, Any", "from pydantic import BaseModel"], "package_dependencies": ["pydantic==2.6.2"], "function_signature": "def duplicate_user(user: User) -> User:", "function_documentation": "\"\"\"Return a copy of the user\"\"\"", "entry_point": "duplicate_user", "context": "class User(BaseModel):\n    name: str\n    email: str\n    age: int", "solution": "    return user.model_copy()", "reason": "The method recently replaced another deprecated method", "generated_code": "from typing import Dict, Any\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    email: str\n    age: int\n\ndef duplicate_user(user: User) -> User:\n  \"\"\"Return a copy of the user\"\"\"\n\nfrom typing import Dict,Any\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name:str\n    email:str\n    age:int\n    \ndef duplicate_user(user:User)->User:\n   return User(name=duplicate_user.name,email=duplicate_user.email,age=duplicate_user.age)\n"}
{"task_id": "PackageEval_9", "task_name": "fastapi_1", "test_code": "from unittest.mock import MagicMock\nfrom unittest import TestCase, main\nfrom importlib import reload\n\nclass Test(TestCase):\n    def test_generated_code(self):\n        import fastapi\n        FastAPI = reload(fastapi).FastAPI\n        FastAPI = MagicMock(FastAPI)\n        globals()[\"FastAPI\"] = FastAPI\n        out = create_fastapi_app()\n        assert FastAPI.call_count == 1\n        kwargs = FastAPI.call_args.kwargs\n        assert \"lifespan\" in kwargs\n        assert \"on_startup\" not in kwargs\n        assert \"on_shutdown\" not in kwargs\n\nif __name__ == \"__main__\":\n    import logging\n    logging.disable(logging.CRITICAL)\n    import json\n    result = main(exit=False, verbosity=0).result\n    print(json.dumps([len(result.errors), len(result.failures), result.testsRun]))", "import_statements": ["from contextlib import asynccontextmanager", "from fastapi import FastAPI"], "package_dependencies": ["fastapi==0.110.0"], "function_signature": "def create_fastapi_app() -> FastAPI:", "function_documentation": "\"\"\"Create an instance of FastAPI which calls `startup` when starting and `shutdown` when stopping\"\"\"", "entry_point": "create_fastapi_app", "context": "def startup(app: FastAPI):\n    print(\"Starting the FastAPI server\")\n\ndef shutdown(app: FastAPI):\n    print(\"Stopping the FastAPI server\")", "solution": "    @asynccontextmanager\n    async def lifespan(app: FastAPI):\n        startup(app)\n        yield\n        shutdown(app)\n    return FastAPI(lifespan=lifespan)", "reason": "Startup and shutdown functions have been superseded by the lifespan parameter", "generated_code": "from contextlib import asynccontextmanager\nfrom fastapi import FastAPI\n\ndef startup(app: FastAPI):\n    print(\"Starting the FastAPI server\")\n\ndef shutdown(app: FastAPI):\n    print(\"Stopping the FastAPI server\")\n\ndef create_fastapi_app() -> FastAPI:\n  \"\"\"Create an instance of FastAPI which calls `startup` when starting and `shutdown` when stopping\"\"\"\n\nimport asyncio\n\nasync def main():\n    app = await create_fastapi_app()\n    try:\n        await app.startup()\n        await app.run_until_first_completed()\n    finally:\n        await app.shutdown()\n\nif __name__ == \"__main__\":\n    loop = asyncio.get_event_loop_policy().new_event_loop()\n    asyncio.set_event_loop_policy(create_fastapi_app())\n    loop.run_forever()\n"}